apiVersion: v1
kind: ConfigMap
metadata:
  name: litellm-config-file
  namespace: litellm
data:
  config.yaml: |
    # Key pool with maximum rate limit rotation
    model_list: 
      # All deployments use same model name "gpt-4" - LiteLLM rotates through them
      - model_name: "gpt-4"
        litellm_params:
          model: "gemini/gemini-2.0-flash"
          api_key: "os.environ/GEMINI_KEY_1"
          rpm: 15
          tpm: 1000000
          
      - model_name: "gpt-4"  
        litellm_params:
          model: "gemini/gemini-1.5-pro"
          api_key: "os.environ/GEMINI_KEY_1"
          rpm: 10
          tpm: 600000
          
      - model_name: "gpt-4"
        litellm_params:
          model: "gemini/gemini-2.0-flash"
          api_key: "os.environ/GEMINI_KEY_2"
          rpm: 15
          tpm: 1000000
          
      - model_name: "gpt-4"
        litellm_params:
          model: "gemini/gemini-1.5-pro"
          api_key: "os.environ/GEMINI_KEY_2"
          rpm: 10
          tpm: 600000
    
    # Router settings for key pool rotation
    router_settings:
      routing_strategy: simple-shuffle          # Rotate through all deployments
      num_retries: 4                           # Try all 4 combinations before failing
      timeout: 60                              # Timeout per request
      cooldown_time: 30                        # Cool down failed deployments  
      allowed_fails: 1                         # Try next deployment after 1 failure
    
    # Fallback configuration for rate limit handling
    litellm_settings:
      success_callback: ["langfuse"]           # Optional: track successful requests
      failure_callback: ["langfuse"]           # Optional: track failed requests
      drop_params: true                        # Drop unsupported parameters
      set_verbose: false                       # Reduce logging noise